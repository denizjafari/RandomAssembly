{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Tutorial: BCI Competition IV Dataset 4 Exploration\n",
        "## Working with ECoG Brain Signal Data\n",
        "\n",
        "---\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Download and load the BCI Competition IV Dataset 4 from braindecode\n",
        "- Explore ECoG (Electrocorticography) signal structure\n",
        "- Understand channel configurations and sampling rates\n",
        "- Visualize neural signals in time and frequency domains\n",
        "- Analyze signal characteristics across different brain channels\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Step 1: Data Download\n",
        "\n",
        "We'll download the BCI Competition IV Dataset 4, which contains ECoG recordings from patients performing finger movements.\n",
        "\n",
        "**Data Source:** [BCI Competition IV](http://www.bbci.de/competition/iv/) - Dataset 4\n",
        "- **Dataset:** ECoG recordings from 3 patients\n",
        "- **Task:** Finger flexion movements (5 fingers)\n",
        "- **Channels:** Multiple ECoG electrodes recording brain activity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if not already installed\n",
        "# Uncomment the lines below if you need to install packages\n",
        "# !uv add braindecode moabb\n",
        "# !uv pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and load BCI Competition IV Dataset 4\n",
        "import os\n",
        "from pathlib import Path\n",
        "from braindecode.datasets import BCICompetitionIVDataset4\n",
        "\n",
        "# Download dataset if not already available\n",
        "print(\"Downloading BCI Competition IV Dataset 4...\")\n",
        "try:\n",
        "    BCICompetitionIVDataset4.download()\n",
        "    print(\"‚úì Dataset download complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö† Download error: {e}\")\n",
        "    print(\"Dataset may already be downloaded or there was a connection issue.\")\n",
        "\n",
        "# Check dataset location\n",
        "from main import get_dataset_path\n",
        "base_path, dataset_path = get_dataset_path()\n",
        "print(f\"\\nDataset storage information:\")\n",
        "print(f\"  - Base path: {base_path}\")\n",
        "print(f\"  - Dataset path: {dataset_path}\")\n",
        "print(f\"  - Directory exists: {dataset_path.exists()}\")\n",
        "\n",
        "if dataset_path.exists():\n",
        "    contents = list(dataset_path.iterdir())\n",
        "    if contents:\n",
        "        print(f\"  - Found {len(contents)} items in dataset directory\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 2: Load and Inspect Dataset Structure\n",
        "\n",
        "Now we'll load the dataset and explore its structure, including the number of subjects, channels, and recording characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset for subject 1 (you can change this to [1, 2, 3] for all subjects)\n",
        "subject_ids = 1  # Can be 1, 2, 3, or [1, 2, 3] for all subjects\n",
        "\n",
        "print(f\"Loading dataset for subject(s): {subject_ids}\")\n",
        "dataset = BCICompetitionIVDataset4(subject_ids=subject_ids)\n",
        "\n",
        "print(f\"\\n‚úì Dataset loaded successfully!\")\n",
        "print(f\"  - Number of recordings: {len(dataset.datasets)}\")\n",
        "print(f\"  - Dataset type: {type(dataset).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Quick Data Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the first recording\n",
        "if len(dataset.datasets) > 0:\n",
        "    first_recording = dataset.datasets[0]\n",
        "    print(f\"First recording type: {type(first_recording).__name__}\")\n",
        "    print(f\"First recording description:\\n{first_recording.description}\")\n",
        "    \n",
        "    # Get raw data\n",
        "    raw = first_recording.raw\n",
        "    print(f\"\\nüìä Raw Data Information:\")\n",
        "    print(f\"  - Number of channels: {len(raw.ch_names)}\")\n",
        "    print(f\"  - Sampling frequency: {raw.info['sfreq']} Hz\")\n",
        "    print(f\"  - Duration: {raw.times[-1]:.2f} seconds\")\n",
        "    print(f\"  - Number of time points: {len(raw.times)}\")\n",
        "    print(f\"  - Channel names (first 10): {raw.ch_names[:10]}\")\n",
        "else:\n",
        "    print(\"‚ö† No recordings found in dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the actual ECoG data\n",
        "data, times = raw[:, :]\n",
        "\n",
        "print(f\"üìà Data Shape: {data.shape}\")\n",
        "print(f\"  - Channels: {data.shape[0]}\")\n",
        "print(f\"  - Time points: {data.shape[1]}\")\n",
        "print(f\"  - Time range: {times[0]:.2f} to {times[-1]:.2f} seconds\")\n",
        "\n",
        "print(f\"\\nüìä Data Statistics:\")\n",
        "print(f\"  - Mean: {data.mean():.4f}\")\n",
        "print(f\"  - Std: {data.std():.4f}\")\n",
        "print(f\"  - Min: {data.min():.4f}\")\n",
        "print(f\"  - Max: {data.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìè Step 3: Data Preparation\n",
        "\n",
        "Let's prepare the data for analysis by extracting key information and organizing it into a more convenient format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a summary DataFrame for easier analysis\n",
        "channel_info = []\n",
        "for i, ch_name in enumerate(raw.ch_names):\n",
        "    channel_data = data[i, :]\n",
        "    channel_info.append({\n",
        "        'channel_index': i,\n",
        "        'channel_name': ch_name,\n",
        "        'mean': channel_data.mean(),\n",
        "        'std': channel_data.std(),\n",
        "        'min': channel_data.min(),\n",
        "        'max': channel_data.max(),\n",
        "        'range': channel_data.max() - channel_data.min()\n",
        "    })\n",
        "\n",
        "df_channels = pd.DataFrame(channel_info)\n",
        "\n",
        "print(\"‚úì Channel information extracted\")\n",
        "print(f\"\\nChannel Statistics Summary:\")\n",
        "print(df_channels.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few channels\n",
        "print(\"First 10 channels:\")\n",
        "df_channels.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 4: Data Visualization\n",
        "\n",
        "Let's create comprehensive visualizations to understand the ECoG signals in both time and frequency domains.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Setup Visualization Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "\n",
        "# Set style for prettier plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"‚úì Visualization libraries ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Time Series Visualization - Sample Channels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot first 10 seconds of multiple channels\n",
        "n_channels_to_plot = min(10, len(raw.ch_names))\n",
        "time_mask = times <= 10.0  # First 10 seconds\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "for i in range(n_channels_to_plot):\n",
        "    # Normalize for visualization\n",
        "    channel_data = data[i, time_mask]\n",
        "    channel_data_norm = (channel_data - channel_data.mean()) / (channel_data.std() + 1e-8)\n",
        "    ax.plot(times[time_mask], channel_data_norm + i * 2, \n",
        "            label=raw.ch_names[i], alpha=0.7, linewidth=1)\n",
        "\n",
        "ax.set_xlabel('Time (seconds)', fontsize=12)\n",
        "ax.set_ylabel('Channel (normalized amplitude)', fontsize=12)\n",
        "ax.set_title(f'ECoG Signals - First {n_channels_to_plot} Channels (First 10 seconds)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='upper right', fontsize=8, ncol=2)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Displayed {n_channels_to_plot} channels over first 10 seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Power Spectral Density Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute and plot power spectral density for a sample channel\n",
        "sample_channel_idx = 0\n",
        "sample_channel_data = data[sample_channel_idx, :]\n",
        "\n",
        "# Compute power spectral density using Welch's method\n",
        "freqs, psd = signal.welch(sample_channel_data, fs=raw.info['sfreq'], nperseg=1024)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.semilogy(freqs, psd, linewidth=2, color='steelblue')\n",
        "ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
        "ax.set_ylabel('Power Spectral Density', fontsize=12)\n",
        "ax.set_title(f'Power Spectral Density - Channel: {raw.ch_names[sample_channel_idx]}', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.set_xlim(0, 100)  # Focus on 0-100 Hz range (most relevant for neural signals)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find peak frequency\n",
        "peak_freq_idx = np.argmax(psd[(freqs >= 1) & (freqs <= 100)])\n",
        "peak_freq = freqs[(freqs >= 1) & (freqs <= 100)][peak_freq_idx]\n",
        "print(f\"‚úì Peak frequency: {peak_freq:.2f} Hz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Channel Variability Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot standard deviation across all channels\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar plot of channel standard deviations\n",
        "axes[0].bar(range(len(raw.ch_names)), df_channels['std'], \n",
        "            alpha=0.7, color='coral', edgecolor='black')\n",
        "axes[0].set_xlabel('Channel Index', fontsize=12)\n",
        "axes[0].set_ylabel('Standard Deviation', fontsize=12)\n",
        "axes[0].set_title('Signal Variability Across Channels', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Histogram of channel statistics\n",
        "axes[1].hist(df_channels['std'], bins=30, color='seagreen', alpha=0.7, edgecolor='black')\n",
        "axes[1].set_xlabel('Standard Deviation', fontsize=12)\n",
        "axes[1].set_ylabel('Number of Channels', fontsize=12)\n",
        "axes[1].set_title('Distribution of Channel Variability', fontsize=14, fontweight='bold')\n",
        "axes[1].axvline(df_channels['std'].median(), color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Median: {df_channels[\"std\"].median():.4f}')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Channel variability analysis complete\")\n",
        "print(f\"  - Most variable channel: {df_channels.loc[df_channels['std'].idxmax(), 'channel_name']} (std: {df_channels['std'].max():.4f})\")\n",
        "print(f\"  - Least variable channel: {df_channels.loc[df_channels['std'].idxmin(), 'channel_name']} (std: {df_channels['std'].min():.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Signal Amplitude Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot amplitude distributions for multiple channels\n",
        "n_channels_for_dist = min(5, len(raw.ch_names))\n",
        "\n",
        "fig, axes = plt.subplots(n_channels_for_dist, 1, figsize=(14, 3*n_channels_for_dist))\n",
        "\n",
        "for i in range(n_channels_for_dist):\n",
        "    channel_data = data[i, :]\n",
        "    axes[i].hist(channel_data, bins=50, alpha=0.7, color='mediumpurple', edgecolor='black')\n",
        "    axes[i].set_title(f'Channel {i}: {raw.ch_names[i]}', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel('Amplitude', fontsize=11)\n",
        "    axes[i].set_ylabel('Frequency', fontsize=11)\n",
        "    axes[i].axvline(channel_data.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                    label=f'Mean: {channel_data.mean():.4f}')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Displayed amplitude distributions for {n_channels_for_dist} channels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Correlation Between Channels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute correlation matrix for a subset of channels (for performance)\n",
        "n_channels_corr = min(20, len(raw.ch_names))\n",
        "channel_data_subset = data[:n_channels_corr, :]\n",
        "\n",
        "# Sample every 100th time point for faster computation\n",
        "sample_indices = np.arange(0, channel_data_subset.shape[1], 100)\n",
        "corr_data = channel_data_subset[:, sample_indices].T\n",
        "\n",
        "# Compute correlation\n",
        "correlation_matrix = np.corrcoef(corr_data.T)\n",
        "\n",
        "# Plot correlation heatmap\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "im = ax.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "ax.set_xticks(range(n_channels_corr))\n",
        "ax.set_yticks(range(n_channels_corr))\n",
        "ax.set_xticklabels([raw.ch_names[i] for i in range(n_channels_corr)], rotation=45, ha='right')\n",
        "ax.set_yticklabels([raw.ch_names[i] for i in range(n_channels_corr)])\n",
        "ax.set_title(f'Channel Correlation Matrix (First {n_channels_corr} channels)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im, ax=ax, label='Correlation Coefficient')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Correlation analysis complete for {n_channels_corr} channels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Step 5: Save Processed Data\n",
        "\n",
        "Let's save the processed channel information for future use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save channel information to CSV\n",
        "output_dir = Path(\"output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "output_file = output_dir / \"bci_channel_info.csv\"\n",
        "df_channels.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"‚úì Channel information saved to: {output_file}\")\n",
        "print(f\"  - Total channels: {len(df_channels)}\")\n",
        "print(f\"  - Columns: {list(df_channels.columns)}\")\n",
        "\n",
        "# Also save a summary\n",
        "summary = {\n",
        "    'subject_id': subject_ids,\n",
        "    'num_channels': len(raw.ch_names),\n",
        "    'sampling_freq': raw.info['sfreq'],\n",
        "    'duration_seconds': times[-1],\n",
        "    'num_timepoints': len(times),\n",
        "    'data_mean': data.mean(),\n",
        "    'data_std': data.std(),\n",
        "    'data_min': data.min(),\n",
        "    'data_max': data.max()\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame([summary])\n",
        "summary_file = output_dir / \"bci_dataset_summary.csv\"\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "print(f\"‚úì Dataset summary saved to: {summary_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéØ Ready for Time Series Forecasting!\n",
        "\n",
        "Your ECoG data is now explored and ready for forecasting:\n",
        "\n",
        "**Options:**\n",
        "- Use individual channels for univariate time series forecasting\n",
        "- Aggregate multiple channels (mean/median) for composite signals\n",
        "- Apply TimesFM or other forecasting models\n",
        "- Use alternative methods (Linear Regression) on Apple Silicon\n",
        "\n",
        "**Next steps:**\n",
        "- Run `main.py` for complete forecasting pipeline\n",
        "- Explore different channel combinations\n",
        "- Analyze frequency domain features\n",
        "- Build predictive models for finger movement decoding\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Exploration Complete!\n",
        "\n",
        "**What we accomplished:**\n",
        "1. ‚úÖ Downloaded and loaded BCI Competition IV Dataset 4\n",
        "2. ‚úÖ Explored dataset structure and channel information\n",
        "3. ‚úÖ Visualized ECoG signals in time domain\n",
        "4. ‚úÖ Analyzed power spectral density\n",
        "5. ‚úÖ Examined channel variability and correlations\n",
        "6. ‚úÖ Saved processed data for future use\n",
        "\n",
        "**Key Findings:**\n",
        "- Dataset contains multi-channel ECoG recordings\n",
        "- Signals sampled at high frequency (1000 Hz typical)\n",
        "- Channels show varying levels of activity\n",
        "- Ready for time series forecasting analysis\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
