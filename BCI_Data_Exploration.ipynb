{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Tutorial: BCI Competition IV Dataset 4 Exploration\n",
        "## Working with ECoG Brain Signal Data\n",
        "\n",
        "---\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Download and load the BCI Competition IV Dataset 4 from braindecode\n",
        "- Explore ECoG (Electrocorticography) signal structure\n",
        "- Understand channel configurations and sampling rates\n",
        "- Visualize neural signals in time and frequency domains\n",
        "- Analyze signal characteristics across different brain channels\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Step 1: Data Download\n",
        "\n",
        "We'll download the BCI Competition IV Dataset 4, which contains ECoG recordings from patients performing finger movements.\n",
        "\n",
        "**Data Source:** [BCI Competition IV](http://www.bbci.de/competition/iv/) - Dataset 4\n",
        "- **Dataset:** ECoG recordings from 3 patients\n",
        "- **Task:** Finger flexion movements (5 fingers)\n",
        "- **Channels:** Multiple ECoG electrodes recording brain activity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if not already installed\n",
        "# Uncomment the lines below if you need to install packages\n",
        "# !uv add braindecode moabb\n",
        "# !uv pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading BCI Competition IV Dataset 4...\n",
            "‚úì Dataset download complete!\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'main'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset may already be downloaded or there was a connection issue.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Check dataset location\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataset_path\n\u001b[32m     17\u001b[39m base_path, dataset_path = get_dataset_path()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDataset storage information:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'main'"
          ]
        }
      ],
      "source": [
        "# Download and load BCI Competition IV Dataset 4\n",
        "import os\n",
        "from pathlib import Path\n",
        "from braindecode.datasets import BCICompetitionIVDataset4\n",
        "\n",
        "# Hardcoded dataset path\n",
        "MNE_DATA_PATH = Path(\"/workspace/RandomAssembly/mne_data\")\n",
        "\n",
        "# Create dataset directory if it doesn't exist\n",
        "MNE_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Set MNE_DATA_PATH environment variable\n",
        "# This tells MOABB/braindecode where to download the data\n",
        "os.environ['MNE_DATA_PATH'] = str(MNE_DATA_PATH)\n",
        "\n",
        "\n",
        "print(f\"‚úì Set MNE_DATA_PATH to: {os.environ['MNE_DATA_PATH']}\")\n",
        "print(f\"‚úì Directory exists: {MNE_DATA_PATH.exists()}\")\n",
        "\n",
        "# Download dataset if not already available\n",
        "print(\"\\nDownloading BCI Competition IV Dataset 4...\")\n",
        "try:\n",
        "    BCICompetitionIVDataset4.download()\n",
        "    print(\"‚úì Dataset download complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö† Download error: {e}\")\n",
        "    print(\"Dataset may already be downloaded or there was a connection issue.\")\n",
        "\n",
        "# Check dataset location\n",
        "# MOABB stores datasets in moabb/BCICIV4 subdirectory\n",
        "dataset_path = MNE_DATA_PATH / \"moabb\" / \"BCICIV4\"\n",
        "print(f\"\\nDataset storage information:\")\n",
        "print(f\"  - MNE_DATA_PATH: {MNE_DATA_PATH}\")\n",
        "print(f\"  - Dataset path: {dataset_path}\")\n",
        "print(f\"  - Directory exists: {dataset_path.exists()}\")\n",
        "\n",
        "if dataset_path.exists():\n",
        "    contents = list(dataset_path.iterdir())\n",
        "    if contents:\n",
        "        print(f\"  - Found {len(contents)} items in dataset directory\")\n",
        "    else:\n",
        "        print(f\"  - Directory exists but is empty\")\n",
        "else:\n",
        "    print(f\"  - Dataset will be downloaded to: {dataset_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 2: Load and Inspect Dataset Structure\n",
        "\n",
        "Now we'll load the dataset and explore its structure, including the number of subjects, channels, and recording characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset for subject 1 (you can change this to [1, 2, 3] for all subjects)\n",
        "subject_ids = 1  # Can be 1, 2, 3, or [1, 2, 3] for all subjects\n",
        "\n",
        "print(f\"Loading dataset for subject(s): {subject_ids}\")\n",
        "dataset = BCICompetitionIVDataset4(subject_ids=subject_ids)\n",
        "\n",
        "print(f\"\\n‚úì Dataset loaded successfully!\")\n",
        "print(f\"  - Number of recordings: {len(dataset.datasets)}\")\n",
        "print(f\"  - Dataset type: {type(dataset).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Quick Data Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the first recording\n",
        "if len(dataset.datasets) > 0:\n",
        "    first_recording = dataset.datasets[0]\n",
        "    print(f\"First recording type: {type(first_recording).__name__}\")\n",
        "    print(f\"First recording description:\\n{first_recording.description}\")\n",
        "    \n",
        "    # Get raw data\n",
        "    raw = first_recording.raw\n",
        "    print(f\"\\nüìä Raw Data Information:\")\n",
        "    print(f\"  - Number of channels: {len(raw.ch_names)}\")\n",
        "    print(f\"  - Sampling frequency: {raw.info['sfreq']} Hz\")\n",
        "    print(f\"  - Duration: {raw.times[-1]:.2f} seconds\")\n",
        "    print(f\"  - Number of time points: {len(raw.times)}\")\n",
        "    print(f\"  - Channel names (first 10): {raw.ch_names[:10]}\")\n",
        "else:\n",
        "    print(\"‚ö† No recordings found in dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, check what channel types are available\n",
        "print(\"Available channel types in raw data:\")\n",
        "print(f\"  - Channel names: {raw.ch_names[:10]}...\" if len(raw.ch_names) > 10 else f\"  - Channel names: {raw.ch_names}\")\n",
        "\n",
        "# Check channel types\n",
        "channel_types = [raw.get_channel_types()[i] for i in range(len(raw.ch_names))]\n",
        "unique_types = set(channel_types)\n",
        "print(f\"  - Unique channel types: {unique_types}\")\n",
        "\n",
        "# Count each type\n",
        "for ch_type in unique_types:\n",
        "    count = channel_types.count(ch_type)\n",
        "    print(f\"    * {ch_type}: {count} channels\")\n",
        "\n",
        "# Extract ECoG data\n",
        "try:\n",
        "    ecog_picks = raw.pick_types(ecog=True)\n",
        "    ecog_data, ecog_times = ecog_picks[:, :]\n",
        "    ecog_ch_names = ecog_picks.ch_names\n",
        "    print(f\"\\n‚úì ECoG data extracted: {ecog_data.shape[0]} channels, {ecog_data.shape[1]} time points\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö† Error extracting ECoG: {e}\")\n",
        "    # Fallback: use all channels if ECoG picking fails\n",
        "    ecog_data, ecog_times = raw[:, :]\n",
        "    ecog_ch_names = raw.ch_names\n",
        "    print(f\"  Using all channels as ECoG: {ecog_data.shape[0]} channels\")\n",
        "\n",
        "# Extract target data (finger flexions)\n",
        "# According to braindecode example, targets are stored as 'misc' channels\n",
        "# But they might not be available without preprocessing\n",
        "target_data = None\n",
        "target_times = None\n",
        "target_ch_names = None\n",
        "\n",
        "try:\n",
        "    target_picks = raw.pick_types(misc=True)\n",
        "    target_data, target_times = target_picks[:, :]\n",
        "    target_ch_names = target_picks.ch_names\n",
        "    print(f\"‚úì Target data extracted: {target_data.shape[0]} channels, {target_data.shape[1]} time points\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\n‚ö† No 'misc' channels found for targets: {e}\")\n",
        "    print(\"  Note: Target channels may need preprocessing or may be stored differently.\")\n",
        "    print(\"  For now, we'll work with ECoG data only.\")\n",
        "    print(\"  You may need to preprocess the data first (see braindecode example).\")\n",
        "\n",
        "print(f\"\\nüìà ECoG Data Shape: {ecog_data.shape}\")\n",
        "print(f\"  - ECoG Channels: {ecog_data.shape[0]}\")\n",
        "print(f\"  - Time points: {ecog_data.shape[1]}\")\n",
        "print(f\"  - Time range: {ecog_times[0]:.2f} to {ecog_times[-1]:.2f} seconds\")\n",
        "\n",
        "if target_data is not None:\n",
        "    print(f\"\\nüìä Target Data Shape: {target_data.shape}\")\n",
        "    print(f\"  - Target channels (fingers): {target_data.shape[0]}\")\n",
        "    print(f\"  - Target channel names: {target_ch_names}\")\n",
        "    print(f\"  - Target sampling frequency: {raw.info.get('temp', {}).get('target_sfreq', 'N/A')} Hz\")\n",
        "else:\n",
        "    print(f\"\\nüìä Target Data: Not available (no misc channels found)\")\n",
        "\n",
        "print(f\"\\nüìä ECoG Data Statistics:\")\n",
        "print(f\"  - Mean: {ecog_data.mean():.4f}\")\n",
        "print(f\"  - Std: {ecog_data.std():.4f}\")\n",
        "print(f\"  - Min: {ecog_data.min():.4f}\")\n",
        "print(f\"  - Max: {ecog_data.max():.4f}\")\n",
        "\n",
        "if target_data is not None:\n",
        "    print(f\"\\nüìä Target Data Statistics:\")\n",
        "    print(f\"  - Mean: {target_data.mean():.4f}\")\n",
        "    print(f\"  - Std: {target_data.std():.4f}\")\n",
        "    print(f\"  - Min: {target_data.min():.4f}\")\n",
        "    print(f\"  - Max: {target_data.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìè Step 3: Store Data in Pandas DataFrames\n",
        "\n",
        "Let's organize the ECoG signals and finger flexion targets into pandas DataFrames for easier analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame for ECoG time series data\n",
        "# Each column is a channel, each row is a time point\n",
        "df_ecog = pd.DataFrame(ecog_data.T, columns=ecog_ch_names, index=ecog_times)\n",
        "df_ecog.index.name = 'time_seconds'\n",
        "\n",
        "print(\"‚úì ECoG DataFrame created\")\n",
        "print(f\"  - Shape: {df_ecog.shape}\")\n",
        "print(f\"  - Columns (first 5): {list(df_ecog.columns[:5])}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_ecog.head())\n",
        "\n",
        "# Create DataFrame for target (finger flexion) time series if available\n",
        "df_targets = None\n",
        "finger_names = None\n",
        "\n",
        "if target_data is not None and target_ch_names is not None:\n",
        "    finger_names = target_ch_names\n",
        "    df_targets = pd.DataFrame(target_data.T, columns=finger_names, index=target_times)\n",
        "    df_targets.index.name = 'time_seconds'\n",
        "    \n",
        "    print(f\"\\n‚úì Target DataFrame created\")\n",
        "    print(f\"  - Shape: {df_targets.shape}\")\n",
        "    print(f\"  - Columns (fingers): {list(df_targets.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_targets.head())\n",
        "else:\n",
        "    print(f\"\\n‚ö† Target DataFrame not created - no target data available\")\n",
        "    print(\"  You may need to preprocess the data first to access target channels.\")\n",
        "    print(\"  See the braindecode example for preprocessing steps.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary DataFrame for channel statistics\n",
        "channel_info = []\n",
        "for i, ch_name in enumerate(ecog_ch_names):\n",
        "    channel_data = ecog_data[i, :]\n",
        "    channel_info.append({\n",
        "        'channel_index': i,\n",
        "        'channel_name': ch_name,\n",
        "        'channel_type': 'ECoG',\n",
        "        'mean': channel_data.mean(),\n",
        "        'std': channel_data.std(),\n",
        "        'min': channel_data.min(),\n",
        "        'max': channel_data.max(),\n",
        "        'range': channel_data.max() - channel_data.min()\n",
        "    })\n",
        "\n",
        "# Add target channel info\n",
        "for i, ch_name in enumerate(finger_names):\n",
        "    target_channel_data = target_data[i, :]\n",
        "    channel_info.append({\n",
        "        'channel_index': i + len(ecog_ch_names),\n",
        "        'channel_name': ch_name,\n",
        "        'channel_type': 'Target',\n",
        "        'mean': target_channel_data.mean(),\n",
        "        'std': target_channel_data.std(),\n",
        "        'min': target_channel_data.min(),\n",
        "        'max': target_channel_data.max(),\n",
        "        'range': target_channel_data.max() - target_channel_data.min()\n",
        "    })\n",
        "\n",
        "df_channels = pd.DataFrame(channel_info)\n",
        "\n",
        "print(\"‚úì Channel information DataFrame created\")\n",
        "print(f\"\\nChannel Statistics Summary:\")\n",
        "print(df_channels.groupby('channel_type').describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 4: Data Visualization\n",
        "\n",
        "Let's create comprehensive visualizations to understand the ECoG signals in both time and frequency domains.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Setup Visualization Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "\n",
        "# Set style for prettier plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"‚úì Visualization libraries ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Time Series Visualization - Sample Channels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot first 10 seconds of multiple channels\n",
        "n_channels_to_plot = min(10, len(raw.ch_names))\n",
        "time_mask = times <= 10.0  # First 10 seconds\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "for i in range(n_channels_to_plot):\n",
        "    # Normalize for visualization\n",
        "    channel_data = data[i, time_mask]\n",
        "    channel_data_norm = (channel_data - channel_data.mean()) / (channel_data.std() + 1e-8)\n",
        "    ax.plot(times[time_mask], channel_data_norm + i * 2, \n",
        "            label=raw.ch_names[i], alpha=0.7, linewidth=1)\n",
        "\n",
        "ax.set_xlabel('Time (seconds)', fontsize=12)\n",
        "ax.set_ylabel('Channel (normalized amplitude)', fontsize=12)\n",
        "ax.set_title(f'ECoG Signals - First {n_channels_to_plot} Channels (First 10 seconds)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='upper right', fontsize=8, ncol=2)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Displayed {n_channels_to_plot} channels over first 10 seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Finger Flexion Targets Visualization\n",
        "\n",
        "Visualize the finger flexion targets (time series) as shown in the braindecode example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot finger flexion targets over time (if available)\n",
        "if df_targets is not None and finger_names is not None:\n",
        "    # Use first 30 seconds for visualization (as in braindecode example)\n",
        "    time_limit = 30.0\n",
        "    time_mask = df_targets.index <= time_limit\n",
        "\n",
        "    fig, axes = plt.subplots(len(finger_names), 1, figsize=(14, 3*len(finger_names)), sharex=True)\n",
        "\n",
        "    if len(finger_names) == 1:\n",
        "        axes = [axes]  # Make it iterable for single finger case\n",
        "\n",
        "    for i, finger in enumerate(finger_names):\n",
        "        axes[i].plot(df_targets.index[time_mask], df_targets[finger][time_mask], \n",
        "                     linewidth=2, label=f'{finger}', color=plt.cm.tab10(i))\n",
        "        axes[i].set_ylabel('Finger Flexion', fontsize=11)\n",
        "        axes[i].set_title(f'{finger}', fontsize=12, fontweight='bold')\n",
        "        axes[i].legend()\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[-1].set_xlabel('Time (seconds)', fontsize=12)\n",
        "    fig.suptitle('Finger Flexion Targets (Time Series)', fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"‚úì Displayed finger flexion targets for {len(finger_names)} fingers\")\n",
        "    print(f\"  - Time range: 0 to {time_limit} seconds\")\n",
        "    print(f\"  - Target sampling frequency: {raw.info.get('temp', {}).get('target_sfreq', 'N/A')} Hz\")\n",
        "else:\n",
        "    print(\"‚ö† Target data not available for visualization\")\n",
        "    print(\"  Target channels may need preprocessing first.\")\n",
        "    print(\"  See the braindecode example for preprocessing steps to access finger flexion targets.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Power Spectral Density Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute and plot power spectral density for a sample ECoG channel\n",
        "sample_channel_idx = 0\n",
        "sample_channel_data = ecog_data[sample_channel_idx, :]\n",
        "\n",
        "# Compute power spectral density using Welch's method\n",
        "freqs, psd = signal.welch(sample_channel_data, fs=raw.info['sfreq'], nperseg=1024)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.semilogy(freqs, psd, linewidth=2, color='steelblue')\n",
        "ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
        "ax.set_ylabel('Power Spectral Density', fontsize=12)\n",
        "ax.set_title(f'Power Spectral Density - Channel: {ecog_ch_names[sample_channel_idx]}', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.set_xlim(0, 100)  # Focus on 0-100 Hz range (most relevant for neural signals)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find peak frequency\n",
        "peak_freq_idx = np.argmax(psd[(freqs >= 1) & (freqs <= 100)])\n",
        "peak_freq = freqs[(freqs >= 1) & (freqs <= 100)][peak_freq_idx]\n",
        "print(f\"‚úì Peak frequency: {peak_freq:.2f} Hz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Channel Variability Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot standard deviation across all ECoG channels\n",
        "ecog_channels_df = df_channels[df_channels['channel_type'] == 'ECoG']\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar plot of channel standard deviations\n",
        "axes[0].bar(range(len(ecog_channels_df)), ecog_channels_df['std'], \n",
        "            alpha=0.7, color='coral', edgecolor='black')\n",
        "axes[0].set_xlabel('Channel Index', fontsize=12)\n",
        "axes[0].set_ylabel('Standard Deviation', fontsize=12)\n",
        "axes[0].set_title('Signal Variability Across ECoG Channels', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Histogram of channel statistics\n",
        "axes[1].hist(ecog_channels_df['std'], bins=30, color='seagreen', alpha=0.7, edgecolor='black')\n",
        "axes[1].set_xlabel('Standard Deviation', fontsize=12)\n",
        "axes[1].set_ylabel('Number of Channels', fontsize=12)\n",
        "axes[1].set_title('Distribution of ECoG Channel Variability', fontsize=14, fontweight='bold')\n",
        "axes[1].axvline(ecog_channels_df['std'].median(), color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Median: {ecog_channels_df[\"std\"].median():.4f}')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Channel variability analysis complete\")\n",
        "most_var = ecog_channels_df.loc[ecog_channels_df['std'].idxmax()]\n",
        "least_var = ecog_channels_df.loc[ecog_channels_df['std'].idxmin()]\n",
        "print(f\"  - Most variable channel: {most_var['channel_name']} (std: {most_var['std']:.4f})\")\n",
        "print(f\"  - Least variable channel: {least_var['channel_name']} (std: {least_var['std']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Target Distribution Analysis\n",
        "\n",
        "Analyze the distribution of finger flexion values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot distributions of finger flexion targets (if available)\n",
        "if df_targets is not None and finger_names is not None:\n",
        "    fig, axes = plt.subplots(1, len(finger_names), figsize=(4*len(finger_names), 5))\n",
        "    if len(finger_names) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, finger in enumerate(finger_names):\n",
        "        axes[i].hist(df_targets[finger], bins=50, alpha=0.7, color=plt.cm.tab10(i), edgecolor='black')\n",
        "        axes[i].set_title(f'{finger}', fontsize=12, fontweight='bold')\n",
        "        axes[i].set_xlabel('Finger Flexion Value', fontsize=11)\n",
        "        axes[i].set_ylabel('Frequency', fontsize=11)\n",
        "        axes[i].axvline(df_targets[finger].mean(), color='red', linestyle='--', linewidth=2,\n",
        "                        label=f'Mean: {df_targets[finger].mean():.4f}')\n",
        "        axes[i].legend()\n",
        "        axes[i].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.suptitle('Distribution of Finger Flexion Targets', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"‚úì Target distribution analysis complete\")\n",
        "    for finger in finger_names:\n",
        "        print(f\"  - {finger}: mean={df_targets[finger].mean():.4f}, std={df_targets[finger].std():.4f}\")\n",
        "else:\n",
        "    print(\"‚ö† Target data not available for distribution analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.7 Correlation Between ECoG Channels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute correlation matrix for a subset of ECoG channels (for performance)\n",
        "n_channels_corr = min(20, len(ecog_ch_names))\n",
        "\n",
        "# Sample every 100th time point for faster computation\n",
        "sample_indices = np.arange(0, df_ecog.shape[0], 100)\n",
        "corr_data = df_ecog.iloc[sample_indices, :n_channels_corr]\n",
        "\n",
        "# Compute correlation\n",
        "correlation_matrix = corr_data.corr().values\n",
        "\n",
        "# Plot correlation heatmap\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "im = ax.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "ax.set_xticks(range(n_channels_corr))\n",
        "ax.set_yticks(range(n_channels_corr))\n",
        "ax.set_xticklabels(ecog_ch_names[:n_channels_corr], rotation=45, ha='right', fontsize=8)\n",
        "ax.set_yticklabels(ecog_ch_names[:n_channels_corr], fontsize=8)\n",
        "ax.set_title(f'ECoG Channel Correlation Matrix (First {n_channels_corr} channels)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im, ax=ax, label='Correlation Coefficient')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Correlation analysis complete for {n_channels_corr} ECoG channels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.8 Correlation Between Targets (Fingers)\n",
        "\n",
        "Analyze how finger flexions correlate with each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute correlation between finger flexions (if available)\n",
        "if df_targets is not None and finger_names is not None and len(finger_names) > 1:\n",
        "    target_correlation = df_targets.corr()\n",
        "\n",
        "    # Plot correlation heatmap\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    im = ax.imshow(target_correlation.values, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "    ax.set_xticks(range(len(finger_names)))\n",
        "    ax.set_yticks(range(len(finger_names)))\n",
        "    ax.set_xticklabels(finger_names, rotation=45, ha='right')\n",
        "    ax.set_yticklabels(finger_names)\n",
        "    ax.set_title('Correlation Between Finger Flexions', fontsize=14, fontweight='bold')\n",
        "    plt.colorbar(im, ax=ax, label='Correlation Coefficient')\n",
        "\n",
        "    # Add correlation values as text\n",
        "    for i in range(len(finger_names)):\n",
        "        for j in range(len(finger_names)):\n",
        "            text = ax.text(j, i, f'{target_correlation.iloc[i, j]:.2f}',\n",
        "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"‚úì Target correlation analysis complete\")\n",
        "    print(f\"\\nCorrelation matrix:\")\n",
        "    print(target_correlation)\n",
        "else:\n",
        "    print(\"‚ö† Target data not available or insufficient for correlation analysis\")\n",
        "    if df_targets is not None and len(finger_names) == 1:\n",
        "        print(\"  Only one finger target available - correlation not applicable\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Step 5: Save Processed Data\n",
        "\n",
        "Let's save the processed channel information for future use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save channel information to CSV\n",
        "output_dir = Path(\"output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "output_file = output_dir / \"bci_channel_info.csv\"\n",
        "df_channels.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"‚úì Channel information saved to: {output_file}\")\n",
        "print(f\"  - Total channels: {len(df_channels)}\")\n",
        "print(f\"  - Columns: {list(df_channels.columns)}\")\n",
        "\n",
        "# Also save a summary\n",
        "summary = {\n",
        "    'subject_id': subject_ids,\n",
        "    'num_channels': len(raw.ch_names),\n",
        "    'sampling_freq': raw.info['sfreq'],\n",
        "    'duration_seconds': times[-1],\n",
        "    'num_timepoints': len(times),\n",
        "    'data_mean': data.mean(),\n",
        "    'data_std': data.std(),\n",
        "    'data_min': data.min(),\n",
        "    'data_max': data.max()\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame([summary])\n",
        "summary_file = output_dir / \"bci_dataset_summary.csv\"\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "print(f\"‚úì Dataset summary saved to: {summary_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéØ Ready for Time Series Forecasting!\n",
        "\n",
        "Your ECoG data is now explored and ready for forecasting:\n",
        "\n",
        "**Options:**\n",
        "- Use individual channels for univariate time series forecasting\n",
        "- Aggregate multiple channels (mean/median) for composite signals\n",
        "- Apply TimesFM or other forecasting models\n",
        "- Use alternative methods (Linear Regression) on Apple Silicon\n",
        "\n",
        "**Next steps:**\n",
        "- Run `main.py` for complete forecasting pipeline\n",
        "- Explore different channel combinations\n",
        "- Analyze frequency domain features\n",
        "- Build predictive models for finger movement decoding\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Exploration Complete!\n",
        "\n",
        "**What we accomplished:**\n",
        "1. ‚úÖ Downloaded and loaded BCI Competition IV Dataset 4\n",
        "2. ‚úÖ Explored dataset structure and channel information\n",
        "3. ‚úÖ Visualized ECoG signals in time domain\n",
        "4. ‚úÖ Analyzed power spectral density\n",
        "5. ‚úÖ Examined channel variability and correlations\n",
        "6. ‚úÖ Saved processed data for future use\n",
        "\n",
        "**Key Findings:**\n",
        "- Dataset contains multi-channel ECoG recordings\n",
        "- Signals sampled at high frequency (1000 Hz typical)\n",
        "- Channels show varying levels of activity\n",
        "- Ready for time series forecasting analysis\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
